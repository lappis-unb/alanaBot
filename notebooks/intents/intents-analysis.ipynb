{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kO9wt2g3okLS"
   },
   "source": [
    "# Análise das Intents\n",
    "\n",
    "Este jupyter-notebook vai auxiliar na análise de detecção de intenções de seu chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasa_nlu: 0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "import rasa_nlu\n",
    "print(\"rasa_nlu: {}\".format(rasa_nlu.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xeXgpdwzOAl"
   },
   "source": [
    "### Treinando o modelo do Rasa NLU\n",
    "\n",
    "* Para avaliar o bot o primeiro passo é treiner o seu chatbot. Mas não é necessário treinar a parte de conversão completa (rasa_core) apenas a parte de interpretação de mensagens (rasa_nlu).\n",
    "\n",
    "* O comando `train-nlu` do Makefile executa o treinamento apenas do `rasa_nlu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/work/bot'\n",
      "python3 -m rasa_nlu.train -c nlu_config.yml --fixed_model_name current \\\n",
      "  --data data/intents/ -o models --project nlu --verbose\n",
      "/usr/local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/usr/local/lib/python3.6/runpy.py:125: RuntimeWarning: 'rasa_nlu.train' found in sys.modules after import of package 'rasa_nlu', but prior to execution of 'rasa_nlu.train'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of data/intents/aleatorio.md is md\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 197 (24 distinct intents)\n",
      "\t- Found intents: 'historia', 'de_onde_voce_eh', 'triste', 'filhos', 'hobby', 'signo', 'como_estou', 'piada', 'playlist', 'time', 'genero', 'relationship', 'bff', 'esporte', 'risada', 'star_wars', 'religiao', 'cor', 'linguagens', 'filme', 'me', 'onde_voce_mora', 'comida', 'license'\n",
      "\t- entity examples: 172 (22 distinct entities)\n",
      "\t- found entities: 'historia', 'filhos', 'hobby', 'playlist', 'genero', 'esporte', 'linguagens', 'filme', 'me', 'where', 'comida', 'triste', 'signo', 'starwars', 'piada', 'how', 'relationship', 'bff', 'live', 'religiao', 'cor', 'license'\n",
      "\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of data/intents/actions.md is md\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 6 (1 distinct intents)\n",
      "\t- Found intents: 'action_test'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of data/intents/geral.md is md\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 85 (7 distinct intents)\n",
      "\t- Found intents: 'elogios', 'out_of_scope', 'negar', 'despedir', 'diga_mais', 'cumprimentar', 'tudo_bem'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 288 (32 distinct intents)\n",
      "\t- Found intents: 'historia', 'de_onde_voce_eh', 'out_of_scope', 'filhos', 'hobby', 'playlist', 'diga_mais', 'genero', 'esporte', 'star_wars', 'negar', 'linguagens', 'filme', 'me', 'comida', 'elogios', 'triste', 'signo', 'como_estou', 'piada', 'time', 'relationship', 'tudo_bem', 'bff', 'risada', 'action_test', 'religiao', 'despedir', 'cor', 'onde_voce_mora', 'cumprimentar', 'license'\n",
      "\t- entity examples: 172 (22 distinct entities)\n",
      "\t- found entities: 'historia', 'filhos', 'hobby', 'playlist', 'genero', 'esporte', 'linguagens', 'filme', 'me', 'where', 'comida', 'triste', 'signo', 'starwars', 'piada', 'how', 'relationship', 'bff', 'live', 'religiao', 'cor', 'license'\n",
      "\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component WhitespaceTokenizer\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CRFEntityExtractor\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EntitySynonymMapper\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:31 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
      "2019-05-03 21:20:32 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:32 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EmbeddingIntentClassifier\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2019-05-03 21:20:32 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:285: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\u001b[0m\n",
      "2019-05-03 21:20:32 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\u001b[0m\n",
      "2019-05-03 21:20:32 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:286: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\u001b[0m\n",
      "2019-05-03 21:20:32 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "2019-05-03 21:20:32 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\u001b[0m\n",
      "2019-05-03 21:20:32 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "2019-05-03 21:20:33.153976: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-05-03 21:20:33.173206: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2905000000 Hz\n",
      "2019-05-03 21:20:33.173981: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559bc71337e0 executing computations on platform Host. Devices:\n",
      "2019-05-03 21:20:33.174055: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-05-03 21:20:33 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|██████████| 300/300 [00:09<00:00, 30.99it/s, loss=0.115, acc=0.993]\n",
      "2019-05-03 21:20:42 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Finished training embedding classifier, loss=0.115, train accuracy=0.993\n",
      "2019-05-03 21:20:42 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Successfully saved model into '/work/bot/models/nlu/current'\n",
      "2019-05-03 21:20:43 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Finished training\n",
      "make: Leaving directory '/work/bot'\n"
     ]
    }
   ],
   "source": [
    "!make train-nlu -C $BOT_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de avaliação do chatbot\n",
    "\n",
    "* O Rasa fornece vários métodos de avaliação e validação das `intents`, para verificar como utiliza-los, cada método fornece um log, imagem, gráfico ou arquivo com dados relevantes para interpretação do chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O comando `!python -m rasa_nlu.test` é a base para a avaliação do chatbot.\n",
    "\n",
    "* Na célula abaixo a flag `-h` foi utilizada para mostrar as funções e a forma de uso de cada uma delas, mude seus valores e flags para ter as informações desejadas na sua análise.\n",
    "\n",
    "* Atualmente o Rasa possui 2 modos, `evaluation` e `crossvalidation` que tem seções decicadas a eles neste jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/usr/local/lib/python3.6/runpy.py:125: RuntimeWarning: 'rasa_nlu.test' found in sys.modules after import of package 'rasa_nlu', but prior to execution of 'rasa_nlu.test'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "usage: test.py [-h] [--debug] [-v] -d DATA [--mode MODE] [-c CONFIG]\n",
      "               [-m MODEL] [-f FOLDS] [--report [REPORT]]\n",
      "               [--successes [SUCCESSES]] [--errors ERRORS]\n",
      "               [--histogram HISTOGRAM] [--confmat CONFMAT]\n",
      "\n",
      "evaluate a Rasa NLU pipeline with cross validation or on external data\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --debug               Print lots of debugging statements. Sets logging level\n",
      "                        to DEBUG\n",
      "  -v, --verbose         Be verbose. Sets logging level to INFO\n",
      "  -d DATA, --data DATA  file containing training/evaluation data\n",
      "  --mode MODE           evaluation|crossvalidation (evaluate pretrained model\n",
      "                        or train model by crossvalidation)\n",
      "  -c CONFIG, --config CONFIG\n",
      "                        model configuration file (crossvalidation only)\n",
      "  -m MODEL, --model MODEL\n",
      "                        path to model (evaluation only)\n",
      "  -f FOLDS, --folds FOLDS\n",
      "                        number of CV folds (crossvalidation only)\n",
      "  --report [REPORT]     output path to save the intent/entitymetrics report\n",
      "  --successes [SUCCESSES]\n",
      "                        output path to save successful predictions\n",
      "  --errors ERRORS       output path to save model errors\n",
      "  --histogram HISTOGRAM\n",
      "                        output path for the confidence histogram\n",
      "  --confmat CONFMAT     output path for the confusion matrix plot\n"
     ]
    }
   ],
   "source": [
    "!python -m rasa_nlu.test -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O comando abaixo gera informações relevates para a validação das `intents` são elas:\n",
    "    * Matriz de confuzão\n",
    "    * Histograma\n",
    "    * Erros de intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/usr/local/lib/python3.6/runpy.py:125: RuntimeWarning: 'rasa_nlu.test' found in sys.modules after import of package 'rasa_nlu', but prior to execution of 'rasa_nlu.test'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2019-05-03 21:20:46.960890: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-05-03 21:20:46.979691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2905000000 Hz\n",
      "2019-05-03 21:20:46.979956: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x565180f44560 executing computations on platform Host. Devices:\n",
      "2019-05-03 21:20:46.979989: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-05-03 21:20:47 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\u001b[0m\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mtensorflow\u001b[0m  - Restoring parameters from ../../bot/models/nlu/current/component_4_EmbeddingIntentClassifier.ckpt\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../bot/data/intents/aleatorio.md is md\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 197 (24 distinct intents)\n",
      "\t- Found intents: 'de_onde_voce_eh', 'me', 'esporte', 'risada', 'cor', 'signo', 'hobby', 'star_wars', 'linguagens', 'triste', 'historia', 'religiao', 'time', 'filme', 'relationship', 'onde_voce_mora', 'genero', 'playlist', 'bff', 'piada', 'filhos', 'license', 'comida', 'como_estou'\n",
      "\t- entity examples: 172 (22 distinct entities)\n",
      "\t- found entities: 'signo', 'triste', 'linguagens', 'live', 'filme', 'relationship', 'where', 'genero', 'playlist', 'bff', 'starwars', 'piada', 'filhos', 'license', 'comida', 'me', 'esporte', 'cor', 'hobby', 'religiao', 'how', 'historia'\n",
      "\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../bot/data/intents/actions.md is md\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 6 (1 distinct intents)\n",
      "\t- Found intents: 'action_test'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../bot/data/intents/geral.md is md\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 85 (7 distinct intents)\n",
      "\t- Found intents: 'elogios', 'cumprimentar', 'out_of_scope', 'despedir', 'negar', 'tudo_bem', 'diga_mais'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 288 (32 distinct intents)\n",
      "\t- Found intents: 'action_test', 'elogios', 'out_of_scope', 'signo', 'star_wars', 'linguagens', 'triste', 'diga_mais', 'filme', 'relationship', 'onde_voce_mora', 'genero', 'playlist', 'cumprimentar', 'bff', 'piada', 'filhos', 'license', 'comida', 'como_estou', 'de_onde_voce_eh', 'me', 'esporte', 'risada', 'cor', 'despedir', 'hobby', 'tudo_bem', 'religiao', 'time', 'negar', 'historia'\n",
      "\t- entity examples: 172 (22 distinct entities)\n",
      "\t- found entities: 'signo', 'triste', 'linguagens', 'live', 'filme', 'relationship', 'where', 'genero', 'playlist', 'bff', 'starwars', 'piada', 'filhos', 'license', 'comida', 'me', 'esporte', 'cor', 'hobby', 'religiao', 'how', 'historia'\n",
      "\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Running model for predictions:\n",
      "100%|████████████████████████████████████████| 288/288 [00:00<00:00, 561.88it/s]\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Intent evaluation results:\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Intent Evaluation: Only considering those 288 examples that have a defined intent out of 288 examples\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - F1-Score:  0.9914054566832343\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Precision: 0.9942129629629629\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Accuracy:  0.9895833333333334\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "                      0.00      0.00      0.00         0\n",
      "    action_test       1.00      1.00      1.00         6\n",
      "            bff       1.00      1.00      1.00        11\n",
      "         comida       1.00      1.00      1.00         8\n",
      "     como_estou       1.00      1.00      1.00         8\n",
      "            cor       1.00      1.00      1.00         6\n",
      "   cumprimentar       1.00      0.91      0.95        22\n",
      "de_onde_voce_eh       1.00      1.00      1.00         4\n",
      "       despedir       1.00      1.00      1.00        16\n",
      "      diga_mais       1.00      1.00      1.00         9\n",
      "        elogios       1.00      1.00      1.00         4\n",
      "        esporte       1.00      1.00      1.00         6\n",
      "         filhos       1.00      1.00      1.00        11\n",
      "          filme       1.00      1.00      1.00         4\n",
      "         genero       1.00      1.00      1.00         8\n",
      "       historia       1.00      1.00      1.00         6\n",
      "          hobby       1.00      1.00      1.00         7\n",
      "        license       1.00      1.00      1.00        11\n",
      "     linguagens       1.00      0.93      0.96        14\n",
      "             me       1.00      1.00      1.00         6\n",
      "          negar       1.00      1.00      1.00        19\n",
      " onde_voce_mora       1.00      1.00      1.00         8\n",
      "   out_of_scope       1.00      1.00      1.00         5\n",
      "          piada       1.00      1.00      1.00         7\n",
      "       playlist       1.00      1.00      1.00         8\n",
      "   relationship       1.00      1.00      1.00        10\n",
      "       religiao       1.00      1.00      1.00        16\n",
      "         risada       1.00      1.00      1.00        13\n",
      "          signo       1.00      1.00      1.00         3\n",
      "      star_wars       1.00      1.00      1.00        10\n",
      "           time       1.00      1.00      1.00         5\n",
      "         triste       1.00      1.00      1.00         7\n",
      "       tudo_bem       0.83      1.00      0.91        10\n",
      "\n",
      "      micro avg       0.99      0.99      0.99       288\n",
      "      macro avg       0.96      0.96      0.96       288\n",
      "   weighted avg       0.99      0.99      0.99       288\n",
      "\n",
      "2019-05-03 21:20:47 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Model prediction errors saved to errors.json.\n",
      "2019-05-03 21:20:49 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Confusion matrix, without normalization: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 11 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  5  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0 10]]\n",
      "Figure(2000x2000)\n",
      "Figure(1000x1000)\n",
      "2019-05-03 21:20:54 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Entity evaluation results:\n",
      "2019-05-03 21:20:54 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Evaluation for entity extractor: CRFEntityExtractor \n",
      "2019-05-03 21:20:54 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - F1-Score:  1.0\n",
      "2019-05-03 21:20:54 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Precision: 1.0\n",
      "2019-05-03 21:20:54 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Accuracy:  1.0\n",
      "2019-05-03 21:20:54 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bff       1.00      1.00      1.00        17\n",
      "      comida       1.00      1.00      1.00        17\n",
      "         cor       1.00      1.00      1.00        13\n",
      "     esporte       1.00      1.00      1.00         6\n",
      "      filhos       1.00      1.00      1.00        11\n",
      "       filme       1.00      1.00      1.00         4\n",
      "      genero       1.00      1.00      1.00        15\n",
      "    historia       1.00      1.00      1.00         6\n",
      "       hobby       1.00      1.00      1.00        11\n",
      "         how       1.00      1.00      1.00        24\n",
      "     license       1.00      1.00      1.00        14\n",
      "  linguagens       1.00      1.00      1.00        14\n",
      "        live       1.00      1.00      1.00        13\n",
      "          me       1.00      1.00      1.00         6\n",
      "   no_entity       1.00      1.00      1.00       613\n",
      "       piada       1.00      1.00      1.00         7\n",
      "    playlist       1.00      1.00      1.00         7\n",
      "relationship       1.00      1.00      1.00         9\n",
      "    religiao       1.00      1.00      1.00        16\n",
      "       signo       1.00      1.00      1.00         3\n",
      "    starwars       1.00      1.00      1.00        13\n",
      "      triste       1.00      1.00      1.00         7\n",
      "       where       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       849\n",
      "   macro avg       1.00      1.00      1.00       849\n",
      "weighted avg       1.00      1.00      1.00       849\n",
      "\n",
      "2019-05-03 21:20:54 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Finished evaluation\n"
     ]
    }
   ],
   "source": [
    "!python -m rasa_nlu.test -d $BOT_INTENTS_PATH -m $BOT_MODELS_NLU_PATH --mode evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confuzão\n",
    "* A matriz de confuzão mostra a correlação entre as intents.\n",
    "* A diagonal principal tem forte correlação pois mostra a relação de uma intent **com ela mesma**\n",
    "* O ideal é que não haja **nenhum valor** diferente de **0 fora da diagonal principal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"700\"\n",
       "            src=\"./confmat.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8f7bb13630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./confmat.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erros\n",
    "* O arquivo `erros,json` mostra os erros encontrados. Este arquivo lista os mesmos erros mostrados na **matriz de confuzão**, então caso ela fique muito grande, não se preocupe, pois você pode apenas procurar os erros no arquivo gerado.\n",
    "* Os erros mostrados são textos repetidos nos exemplos de diferrentes `intents`.\n",
    "* Caso o arquivo não seja gerado significa que não foram encontrados erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "    {\r\n",
      "        \"text\": \"e o c#\",\r\n",
      "        \"intent\": \"linguagens\",\r\n",
      "        \"intent_prediction\": {\r\n",
      "            \"name\": \"\",\r\n",
      "            \"confidence\": 0.0\r\n",
      "        }\r\n",
      "    },\r\n",
      "    {\r\n",
      "        \"text\": \"como vai\",\r\n",
      "        \"intent\": \"cumprimentar\",\r\n",
      "        \"intent_prediction\": {\r\n",
      "            \"name\": \"tudo_bem\",\r\n",
      "            \"confidence\": 0.835846483707428\r\n",
      "        }\r\n",
      "    },\r\n",
      "    {\r\n",
      "        \"text\": \"tudo bom\",\r\n",
      "        \"intent\": \"cumprimentar\",\r\n",
      "        \"intent_prediction\": {\r\n",
      "            \"name\": \"tudo_bem\",\r\n",
      "            \"confidence\": 0.8136337995529175\r\n",
      "        }\r\n",
      "    }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "%cat errors.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograma\n",
    "\n",
    "* O histograma contém a distribuição da predições das `intents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"700\"\n",
       "            src=\"./hist.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8f7bb13d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./hist.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/usr/local/lib/python3.6/runpy.py:125: RuntimeWarning: 'rasa_nlu.test' found in sys.modules after import of package 'rasa_nlu', but prior to execution of 'rasa_nlu.test'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2019-05-03 21:20:56 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../bot/data/intents/aleatorio.md is md\n",
      "2019-05-03 21:20:56 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 197 (24 distinct intents)\n",
      "\t- Found intents: 'linguagens', 'triste', 'cor', 'hobby', 'risada', 'bff', 'genero', 'star_wars', 'religiao', 'filhos', 'como_estou', 'me', 'signo', 'historia', 'relationship', 'filme', 'playlist', 'time', 'license', 'piada', 'comida', 'onde_voce_mora', 'esporte', 'de_onde_voce_eh'\n",
      "\t- entity examples: 172 (22 distinct entities)\n",
      "\t- found entities: 'linguagens', 'how', 'hobby', 'starwars', 'filhos', 'me', 'signo', 'relationship', 'where', 'playlist', 'filme', 'license', 'live', 'triste', 'cor', 'bff', 'genero', 'religiao', 'historia', 'piada', 'comida', 'esporte'\n",
      "\n",
      "2019-05-03 21:20:56 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../bot/data/intents/actions.md is md\n",
      "2019-05-03 21:20:56 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 6 (1 distinct intents)\n",
      "\t- Found intents: 'action_test'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-05-03 21:20:56 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../bot/data/intents/geral.md is md\n",
      "2019-05-03 21:20:56 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 85 (7 distinct intents)\n",
      "\t- Found intents: 'despedir', 'diga_mais', 'cumprimentar', 'negar', 'elogios', 'tudo_bem', 'out_of_scope'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-05-03 21:20:57 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 288 (32 distinct intents)\n",
      "\t- Found intents: 'linguagens', 'hobby', 'star_wars', 'filhos', 'out_of_scope', 'me', 'signo', 'relationship', 'filme', 'playlist', 'license', 'elogios', 'tudo_bem', 'action_test', 'de_onde_voce_eh', 'despedir', 'triste', 'cor', 'risada', 'negar', 'bff', 'genero', 'religiao', 'como_estou', 'historia', 'time', 'diga_mais', 'piada', 'cumprimentar', 'comida', 'onde_voce_mora', 'esporte'\n",
      "\t- entity examples: 172 (22 distinct entities)\n",
      "\t- found entities: 'linguagens', 'how', 'hobby', 'starwars', 'filhos', 'me', 'signo', 'relationship', 'where', 'playlist', 'filme', 'license', 'live', 'triste', 'cor', 'bff', 'genero', 'religiao', 'historia', 'piada', 'comida', 'esporte'\n",
      "\n",
      "2019-05-03 21:20:57 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 273 (28 distinct intents)\n",
      "\t- Found intents: 'linguagens', 'despedir', 'triste', 'cor', 'hobby', 'risada', 'negar', 'bff', 'genero', 'star_wars', 'religiao', 'filhos', 'out_of_scope', 'como_estou', 'me', 'historia', 'relationship', 'playlist', 'time', 'license', 'diga_mais', 'piada', 'cumprimentar', 'comida', 'tudo_bem', 'onde_voce_mora', 'esporte', 'action_test'\n",
      "\t- entity examples: 162 (19 distinct entities)\n",
      "\t- found entities: 'triste', 'linguagens', 'live', 'license', 'me', 'cor', 'hobby', 'how', 'bff', 'comida', 'genero', 'piada', 'religiao', 'filhos', 'starwars', 'historia', 'esporte', 'relationship', 'playlist'\n",
      "\n",
      "2019-05-03 21:20:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 131 (28 distinct intents)\n",
      "\t- Found intents: 'linguagens', 'despedir', 'triste', 'cor', 'hobby', 'risada', 'negar', 'bff', 'genero', 'star_wars', 'religiao', 'filhos', 'out_of_scope', 'como_estou', 'me', 'historia', 'relationship', 'playlist', 'time', 'license', 'diga_mais', 'piada', 'cumprimentar', 'comida', 'tudo_bem', 'onde_voce_mora', 'esporte', 'action_test'\n",
      "\t- entity examples: 76 (19 distinct entities)\n",
      "\t- found entities: 'triste', 'linguagens', 'live', 'license', 'me', 'cor', 'hobby', 'how', 'bff', 'comida', 'genero', 'piada', 'religiao', 'filhos', 'starwars', 'historia', 'esporte', 'relationship', 'playlist'\n",
      "\n",
      "2019-05-03 21:20:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 142 (28 distinct intents)\n",
      "\t- Found intents: 'linguagens', 'despedir', 'triste', 'cor', 'hobby', 'risada', 'negar', 'bff', 'genero', 'star_wars', 'religiao', 'filhos', 'out_of_scope', 'como_estou', 'me', 'historia', 'relationship', 'playlist', 'time', 'license', 'diga_mais', 'piada', 'cumprimentar', 'comida', 'tudo_bem', 'onde_voce_mora', 'esporte', 'action_test'\n",
      "\t- entity examples: 86 (19 distinct entities)\n",
      "\t- found entities: 'triste', 'linguagens', 'live', 'license', 'me', 'cor', 'hobby', 'how', 'bff', 'comida', 'genero', 'piada', 'religiao', 'filhos', 'starwars', 'historia', 'esporte', 'relationship', 'playlist'\n",
      "\n",
      "2019-05-03 21:20:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component WhitespaceTokenizer\n",
      "2019-05-03 21:20:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CRFEntityExtractor\n",
      "2019-05-03 21:20:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EntitySynonymMapper\n",
      "2019-05-03 21:20:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
      "2019-05-03 21:20:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:20:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EmbeddingIntentClassifier\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2019-05-03 21:20:59 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:285: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\u001b[0m\n",
      "2019-05-03 21:20:59 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\u001b[0m\n",
      "2019-05-03 21:20:59 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:286: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\u001b[0m\n",
      "2019-05-03 21:20:59 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "2019-05-03 21:21:00 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\u001b[0m\n",
      "2019-05-03 21:21:00 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-03 21:21:00.706185: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-05-03 21:21:00.726392: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2905000000 Hz\n",
      "2019-05-03 21:21:00.726674: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x555b9ee46db0 executing computations on platform Host. Devices:\n",
      "2019-05-03 21:21:00.726702: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-05-03 21:21:00 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|██████████| 300/300 [00:05<00:00, 59.85it/s, loss=0.186, acc=1.000]\n",
      "2019-05-03 21:21:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Finished training embedding classifier, loss=0.186, train accuracy=1.000\n",
      "2019-05-03 21:21:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:21:05 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Running model for predictions:\n",
      "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 353.93it/s]\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Running model for predictions:\n",
      "100%|████████████████████████████████████████| 142/142 [00:00<00:00, 528.87it/s]\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 142 (28 distinct intents)\n",
      "\t- Found intents: 'linguagens', 'despedir', 'triste', 'cor', 'hobby', 'risada', 'negar', 'bff', 'genero', 'star_wars', 'religiao', 'filhos', 'out_of_scope', 'como_estou', 'me', 'historia', 'relationship', 'playlist', 'time', 'license', 'diga_mais', 'piada', 'cumprimentar', 'comida', 'tudo_bem', 'onde_voce_mora', 'esporte', 'action_test'\n",
      "\t- entity examples: 86 (19 distinct entities)\n",
      "\t- found entities: 'triste', 'linguagens', 'live', 'license', 'me', 'cor', 'hobby', 'how', 'bff', 'comida', 'genero', 'piada', 'religiao', 'filhos', 'starwars', 'historia', 'esporte', 'relationship', 'playlist'\n",
      "\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 131 (28 distinct intents)\n",
      "\t- Found intents: 'linguagens', 'despedir', 'triste', 'cor', 'hobby', 'risada', 'negar', 'bff', 'genero', 'star_wars', 'religiao', 'filhos', 'out_of_scope', 'como_estou', 'me', 'historia', 'relationship', 'playlist', 'time', 'license', 'diga_mais', 'piada', 'cumprimentar', 'comida', 'tudo_bem', 'onde_voce_mora', 'esporte', 'action_test'\n",
      "\t- entity examples: 76 (19 distinct entities)\n",
      "\t- found entities: 'triste', 'linguagens', 'live', 'license', 'me', 'cor', 'hobby', 'how', 'bff', 'comida', 'genero', 'piada', 'religiao', 'filhos', 'starwars', 'historia', 'esporte', 'relationship', 'playlist'\n",
      "\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component WhitespaceTokenizer\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CRFEntityExtractor\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EntitySynonymMapper\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:21:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EmbeddingIntentClassifier\n",
      "2019-05-03 21:21:07 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|██████████| 300/300 [00:06<00:00, 47.98it/s, loss=0.186, acc=1.000]\n",
      "2019-05-03 21:21:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Finished training embedding classifier, loss=0.186, train accuracy=1.000\n",
      "2019-05-03 21:21:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-05-03 21:21:13 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Running model for predictions:\n",
      "100%|████████████████████████████████████████| 142/142 [00:00<00:00, 520.96it/s]\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Running model for predictions:\n",
      "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 595.66it/s]\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - CV evaluation (n=2)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Intent evaluation results\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - train Accuracy: 0.996 (0.004)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - train F1-score: 0.998 (0.002)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - train Precision: 1.000 (0.000)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - test Accuracy: 0.523 (0.012)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - test F1-score: 0.545 (0.007)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - test Precision: 0.641 (0.014)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Entity evaluation results\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Entity extractor: CRFEntityExtractor\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - train Accuracy: 1.000 (0.000)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - train F1-score: 1.000 (0.000)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - train Precision: 1.000 (0.000)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Entity extractor: CRFEntityExtractor\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - test Accuracy: 0.834 (0.015)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - test F1-score: 0.788 (0.013)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - test Precision: 0.800 (0.015)\n",
      "2019-05-03 21:21:14 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Finished evaluation\n"
     ]
    }
   ],
   "source": [
    "!python -m rasa_nlu.test -d $BOT_INTENTS_PATH -c $BOT_NLU_CONFIG_PATH --mode crossvalidation --folds 2 --report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências:\n",
    "\n",
    "O Rasa está em constante evolução, alguns links úteis para a construção deste jupyter-notebook e para a análise das `intents` são:\n",
    "\n",
    "* [Evaluation](https://rasa.com/docs/nlu/evaluation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "y4miuS-TqYcn",
    "BBF6Nqi9scQE",
    "Fs3nOUzBsqrG",
    "5MnGuFRpzzBh"
   ],
   "default_view": {},
   "name": "Building a Simple Bot with Rasa Stack - Tutorial",
   "provenance": [
    {
     "file_id": "1GutDkDXmfU-nRzNH7Pxxx8YpdvLUw9LO",
     "timestamp": 1521183725373
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
